multi threading

JDK----->compiler(byte code)

JVM----->executor(machine code)

compiler
--------
Javac Test.java

executor(JVM will create process here onwards only)
--------
Java Test


1.process will created
2.JVM instance is allocated for process------------->Interpreter/JIT Compiler --------------->convert byte code to machine code


NOTE:- 

1.in multi threading, we are focusing on JVM only

2.JVM will create process

Hierachy
--------

CPU->JVM->PROCESS->THREADS

Process :- 

1.process is nothing but instace of a program that is getting excuted(Note:- excution only done by JVM only)
2.process has own resources such as memory,thread etc.os allocate resources to process when its created.

Thread :- 

1.thread is nothing but sequence of instructions set in process(threads run independent of cpu)
2.thread is light weight process
3.one process can have multiple threads
4.when process is created,it start with 1 thread and that initial thread is 'main thread' from that we can create multiple
  threads to perform task concurrently.


How much memory does process gets??
---------------------------------

java -Xms512m -Xmx2g MainClassName

NOTE:-
----
1.there is no context switching between thread pool threads
2.there is a context switching between user defined threads
3.each task taking one thread from thread pool to process the task,after process the task then again release back to thread pool
4.completeable future submit tasks to thread pool threads 


JVM(heap,stack,code segment,data segment,registers,program counters)

IMP
---

1.Heap,Code segment,Data segment common for all register,stacks,program counter and threads


2.Register ,stacks,program counters specific to thread only


COMPILE TIME
------------

Bytecode

RUN TIME
--------

1.Process
2.Jvm instace
3.Interpreter/JIT Compiler
4.machine code

QUESTIONS
---------
1.who decide how much over all heap memory allocated for jvm?
2.who decide whatever heap memory we have that is allocated to process?

CODE SEGMENT
------------
1.it contains machine code of the java program
2.machine code is generate after execution of bytecode
3.read only
4.all threads with in the same process,share the same code segment.

DATA SEGMENT
------------
1.contains the GLOBAL and STATIC variables(whatever global variable in code segment).
2.all threads with in the same process,share the same data segment.
3.Threads can read and modify the same data.
4.synchronization is required between multiple threads
      ->if synchronization not there,then data is not consistent.
      ->if synchronization not there,then multiple threads use data segment so data is not consistent.


HEAP
----
1.Objects created at runtime using "new" keyword are allocated in the heap.
  	->threads internall create new objects that is allocated memory in the heap
2.Heap is shared among all the threads of the same process(but not with in process)
	->let say in process1,x8000 heap memory pointing to same location in 
	  physical memory,same x8000 point to different locat‭ion for process2)
3.Threads can read and modify the heap data.
4.synchronization is required between multiple threads.

STACK
-----
1.each thread has its own stack.
2.it manages,method calls,local variables.

REGISTER
--------
1.when JIT(just in time compiles converts the Bytecode into native machine code
  ->it uses register to optimized the generated machine code.
2.Also helps in context switching.
3.each thread has its own register.

COUNTER
-------
1.Also known as Program Counter,it points to the address location of instruction(particular thread) which is getting executed from CODE SEGEMENT.
2.Increments its counter after successfully execution of the instruction.

Execution order
---------------
Code segment->Counter->Thread

NOTE:- All these are managed by JVM



OS schedules(also JVM schedulers) or manages the thread
-------------------------------------------------------

os schedules thread for execution then that is shared to cpu
(in between cpu register and thread register ,there context switching is happening)


SCENARIOS
---------

CPU Cores 2 , Threads 4---------->in this case context switching is need

CPU Cores 2 , Threads 2---------->in this case context switching is no need

CPU Cores 4 , Threads 2---------->in this case context switching is no need

CONTEXT SWITCH TIME
-------------------
CPU and Register take key role

Multi tasking vs Multi threading
--------------------------------

Process 1 and Process 2------------->multi tasking

Thread 1 ,Thread 2 and Thread 3(All threads are in Process 1 only)---------->multi threading

NOTE:-

1.multi tasking do not share the resource
2.multi threading share the resource



Multi threading
---------------
1.allows a program to perform multiple tasks or operation at the same time
2.multiple threads share the same resource such as memory space but still can
  perform task independently

Benefits
--------
1.improved performance by task parallelism
2.Responsiveness
3.Resource sharing

Challenges
----------
1.Concurrency issue like deadlock,data inconsistency etc.
2.Synchronized overhead.
3.Testing and Debugging is difficult.

why we have 2 ways to create threads
------------------------------------

1.class extend only 1 class

2.class implements more than 1 class


runnable interface execution
----------------------------
1.first call run method of thread class
2.internally thread class checks (target!=null) 
  then call the run method of runnable interface implemented class method that is run method


NOTE:-
1.IT industry uses runnable interface 

Thread class execution
----------------------
1.here directly calling the override method in sub class of Thread class

NOTE:-

1.if provided override method in sub class of thread then not involved Thread class run method
2.if not provided override method in sub class of thread then involved default Thread class run method



IMPORTANT POINTS
----------------

runnable interface(not override run method)

thread class(override run method)


Runnable interface------->there is target(concreate class)

Thread class------------>there is no target




Runnable interface----------->We are calling run method on thread class then internally calling concreate class
                              (here concreate class is called as target)

Thread class------------>We are calling run method on concreate class



states(new,runnable,terminated,blocked,waiting,timed waiting)
------
runnable state---------------->(runnable and running)
--------------

not state(running)
---------


new-------->creation

runnable-------->start

runnable-------->start (runnable and running both are different)

blocked--------->file or db operations

waiting-------->wait() and notify()

timed waiting------>Thread.sleep(1000) and join()

stop or teriminate(both are same)



Blocked(file or db operations)------------>Release monitor logs

Waiting------------->Release monitor logs

Timed Waiting(Thread.sleep(1000))------->Do not release monitor logs



start--------->keep it in runnable state(runnable---->waiting for cpu)


runnable(waiting for cpu)-------------->Blocked,Waiting,Timed Waiting

running(got the cpu)


new
---
1.Thread has been created but not started
2.its just an object in memory

runnable
--------
1.Thread is ready to run
2.waiting for cpu time

running
-------
1.when thread start executing its code

blocked
-------
Different scenarios where runnable thread goes into the blocking state
1.i/o:- like reading from file or database
2.lock acquired:- if thread want to lock on a resource which is locked by other thread,it has to wait.
NOTE:- Releases all the MONITOR LOCKS

Waiting
-------
1.Thread goes into this state when we call the wait() method,makes it non-runnable
2.it goes back to runnable,once we call notify() or notifyAll() method
NOTE:- Releases all the MONITOR LOCKS

Timed waiting
-------------
1.Thread waits for specific period of time and comes back to runnable state,after specific conditions met. like sleep() and join()

NOTE:- Do not Releases any MONITOR LOCKS

Terminated
----------
1.life thread is completed ,it can not be started back again.




Monitor lock on-------------->runnable state


Monitor locks------------>using synchronized method or block


Note:- monitor locks priorty for synchronized method or block assuming same


public classs MonitorLockExample{

	public synchronized void task1(){
             //do something
             try{
                 System.out.println("inside task1");
                 Thread.sleep(10000);
             } 
             catch(Exception e){
                //exception handling here
             }
        }
        

        public void task2(){
            System.out.println("task2 , but before synchronized");
            synchronized(this){
                 System.out.println("task2, inside synchronized");
            }
       }
      
     
       public void task3(){
            System.out.println("task3");
       }
}


public static void main(String args[]){
     MonitorLockExample obj=new MonitorLockExample();
     Thread t1=new Thread(()->{ obj.task1(); });
     Thread t2=new Thread(()->{ obj.task2(); });
     Thread t3=new Thread(()->{ obj.task3(); });

     t1.start();
     t2.start();
     t3.start();
}



Monitor locks releases
----------------------

1.blocked(making db calls time)

2.waiting(wait())

Monitor locks not releases
--------------------------

3.timed waiting(Thread.sleep(5000))




Power On
   ↓
CPU executes BIOS
   ↓
OS loads (Linux, Windows, etc.)
   ↓
User runs java -jar
   ↓
OS creates process for JVM
   ↓
JVM starts and runs Spring Boot
   ↓
CPU executes bytecode via JVM





| Component               | Count    | Notes                                          |
| ----------------------- | -------- | ---------------------------------------------- |
| JVM Process             | 1        | Created by OS to run your app                  |
| Main Thread             | 1        | Executes main() method                       |
| Internal Spring Threads | Many     | Tomcat, scheduler, async, etc.                 |
| User-Defined Threads    | Optional | You can create via Thread, ExecutorService |
| Worker Threads          | Many     | Created as needed by Spring or user code       |




Operating System
   └── Starts JVM Process
         └── Runs Spring Boot App (main class)
               ├── Main Thread
               ├── Internal Spring Threads (Tomcat, Scheduler, etc.)
               └── User-Defined Threads (optional)



JVM bytecode
   ↓ (interpreted or JIT compiled)
Native Instructions
   ↓
System Call to OS
   ↓
OS schedules it on CPU
   ↓
CPU executes the code





Thread priority:- it is just hint but not gurrantee to follow the order


Daemon thread:- it is supporting thread such as garbage collector in java,auto save of intellij editor

join()
------

1.in threads,whenever join() applied on the object then that thread execute first.

2.remaining threads holding the execution.



Daemon thread vs user thread
----------------------------

1.Daemon thread uses setter method that used to set flag then only act as Daemon thread

2.User thread not uses setter method that is called user thread



Locks and Semaphores
--------------------

locks do not depend on object like synchronize method


system design

db locks


locks

1.ReentrantLock(same or different object allow at a time only one)
---------------

case 1:- with same object

public class SharedResource{

    boolean isAvailable=false;
    ReentrantLock lock=new ReentrantLock();
    

    public void producer(){
        try{
               lock=lock();
               System.out.println("lock acquired by:"+Thread.currentThread().getName());
               isAvailable=true;
               Thread.sleep(4000);
            }
            catch(Exception e){

            }
            finally{
                 lock.unlock();
                 System.out.printl("Lock release by:"+Thread.currentThread().getName());
            }
    }
}


public class Main{

     public static void Main(String args[]){

         SharedResource resource=new SharedResource();             //with same object

         Thread th1=new Thread(()->{
              resource.producer();
         });

         Thread th2=new Thread(()->{
              resource.producer();
          });
          th1.start();
          th2.start();
     }
}




case 2:- different object

public class SharedResource{

    boolean isAvailable=false;
    

    public void producer(ReentrantLock lock){
        try{
               lock=lock();
               System.out.println("lock acquired by:"+Thread.currentThread().getName());
               isAvailable=true;
               Thread.sleep(4000);
            }
            catch(Exception e){

            }
            finally{
                 lock.unlock();
                 System.out.printl("Lock release by:"+Thread.currentThread().getName());
            }
    }
}


public class Main{

     public static void Main(String args[]){

	 ReentrantLock lock=new ReentrantLock(); 

         SharedResource resource1=new SharedResource();         //with different object

         Thread th1=new Thread(()->{
              resource1.producer(lock);
         });

         SharedResource resource2=new SharedResource();        //with different object

         Thread th2=new Thread(()->{
              resource2.producer(lock);
          });

          th1.start();
          th2.start();
     }
}



ReadWriteLock
-------------

ReadLock(shared lock):- more than 1 thread can acquire the read lock.

WriteLock(exclusive lock):- only 1 thread can acquire the write lock.


IMPORTANT
---------

Read High(1000 times) and Write Low(10 times)


public class SharedResource{

    boolean isAvailable=false;
    

    public void producer(ReadWriteLock lock){
        try{
               lock.readLock().lock();
               System.out.println("Read lock acquired by:"+Thread.currentThread().getName());
               Thread.sleep(4000);
            }
            catch(Exception e){

            }
            finally{
                 lock.readLock().unlock();
                 System.out.printl("Read lock release by:"+Thread.currentThread().getName());
            }
    }


    public void coonsumer(ReadWriteLock lock){
        try{
               lock.writeLock().lock();
               System.out.println("write lock acquired by:"+Thread.currentThread().getName());
               isAvailable=true;
               Thread.sleep(4000);
            }
            catch(Exception e){

            }
            finally{
                 lock.writeLock().unlock();
                 System.out.printl("Write lock release by:"+Thread.currentThread().getName());
            }
    }
}



public class Main{

     public static void Main(String args[]){ 

         SharedResource resource=new SharedResource();         
         ReadWriteLock lock=new ReentrantReadWriteLock();

         Thread th1=new Thread(()->{
              resource.producer(lock);
         });

         Thread th2=new Thread(()->{
              resource.producer(lock);
         });

         SharedResource resource1=new SharedResource();        

         Thread th3=new Thread(()->{
              resource1.consume(lock);
          });

          th1.start();
          th2.start();
          th3.start();
     }
}



StampedLock(Read/Write Lock ,Optimistic Read)
-----------

1.Support Read/Write Lock functionality like ReadWriteLock


types of locks

1.pessimistic locks(synchronized,ReentrantLock,ReadWriteLock(shared/exclusive locks))
2.optimistic locks(no lock acquired)

1.pessimistic locks
-------------------

public class SharedResource{

    boolean isAvailable=false;

    StampedLock lock=new StampedLock();
    

    public void producer(){
        long stamp=lock.readLock();

        try{
               System.out.println("Read lock acquired by:"+Thread.currentThread().getName());
               isAvailable=true;
               Thread.sleep(4000);
            }
            catch(Exception e){

            }
            finally{
                 lock.unlockRead(stamp);
                 System.out.printl("Read lock release by:"+Thread.currentThread().getName());
            }
    }


    public void coonsumer(){

        long stamp=lock.writeLock();

        try{
               System.out.println("write lock acquired by:"+Thread.currentThread().getName());
               isAvailable=false;
            }
            catch(Exception e){

            }
            finally{
                 lock.unlockWrite(stamp);
                 System.out.printl("Write lock release by:"+Thread.currentThread().getName());
            }
    }
}


public class Main{

     public static void Main(String args[]){ 

         SharedResource resource=new SharedResource();         
        
         Thread th1=new Thread(()->{
              resource.producer();
         });

         Thread th2=new Thread(()->{
              resource.producer();
         });       

         Thread th3=new Thread(()->{
              resource.consume();
          });

          th1.start();
          th2.start();
          th3.start();
     }
}


2.optimistic locks(it works on the DB)

public class SharedResource{
  int a=10;
  StampedLock lock=new StampedLock();
  public void producer(){
      long stamp=lock.tryOptimisticRead();
      try{
          System.out.println("Taken optimistic lock");
          a=11;
          Thread.sleep(6000);
          if(lock.validate(stamp)){
              System.out.println("updated a value successfully");
           }
           else {
               System.out.println("rollback of work");
               a=10;//rollback
           }
       }
       catch(Exception e){
       }
    }


     public void consumer(){

          long stamp=lock.writeLock();
          System.out.println("Write lock acquired by:"+Thread.currentThread().getName());
   
          try{
             System.out.println("performing work");
             a=9;
          }
           finally{
              locks.unlockWrite(stamp);
              System.out.println("Write lock released by:"+Thread.currentThread().getName());
          }
     }
}


public class Main{

     public static void Main(String args[]){ 

         SharedResource resource=new SharedResource();         
        
         Thread th1=new Thread(()->{
              resource.producer();
         });    

         Thread th2=new Thread(()->{
              resource.consumer();
          });

          th1.start();
          th2.start();
     }
}


Semaphore Lock
--------------

public class SharedResource{

   boolean isAvailable=false;
  
   Semaphore lock=new Semaphore(2);

   public void producer(){
       
       try{
            lock.acquire();
            System.out.println("Lock acquired by:"+Thread.currentThread().getName());
            isAvailable=true;
            Thread.sleep(4000);
       }
       catch(Exception e){

       }
       finally{
             lock.release();
             System.out.println("Lock release by:"+Thread.currentThread().getName());
       }

}



public class Main{

     public static void Main(String args[]){ 

         SharedResource resource=new SharedResource();         
        
         Thread th1=new Thread(()->{
              resource.producer();
         });    

         Thread th2=new Thread(()->{
              resource.consumer();
          });

         Thread th3=new Thread(()->{
              resource.consumer();
          });


         Thread th4=new Thread(()->{
              resource.consumer();
          });


          th1.start();
          th2.start();
          th3.start();
          th4.start();
     }
}



synchronized(monitor lock----------->wait and notify)



condition
---------

await()------------>wait()

signal()----------->notify()

signalAll()-------->notifyAll()



public class SharedResource {

    boolean isAvailable=false;
    ReentrantLock lock=new ReentrantLock();
    Condition condition=lock.newCondition();

    public void producer(){
       try{
           lock.lock();
           System.out.println("Produce lock acquired by:"+Thread.currentThread().getName());
           if(isAvailable){
              //already available,thread has to wait for it to consume
              System.out.println("Produce thread is waiting:"+Thread.currentThread().getName());
              condition.await();
          }
          isAvailable=true;
          condition.signal();
       }
       catch(Exception e){
       }
        finally{
             lock.unlock();
             System.out.println("Produce lock release by:"+Thread.currentThread().getName());
        }
    }

     public void consume(){
          try{
              Thread.sleep(1000);
              lock.lock();
              System.out.println("Consume lock acquired by:"+Thread.currentThread().getName());
              if(!isAvailable){
                  //already not available , thread has to wait for it to produced
                   System.out.println("Consumer thread is waiting:"+Thread.currentThread().getName());
                   condition.await();
               }
               isAvailable=false;
               condition.signal();
           }
           catch(Exception e){
           }
           finally{
               lock.unlock();
               System.out.println("Consume lock release by:"+Thread.currentThread().getName());
           }
      }
}



public class Main{
    public static void main(String args[]){
         SharedResource resource=new SharedResource();
         Thread th1=new Thread(()->{
             for(int i=0;i<2;i++){
                 resource.producer();
              }
          });

          Thread th2=new Thread(()->{
              for(int i=0;i<2;i++){
                 resource.consume();
              }
          });
 
          th1.start();
          th2.start();
     }
}







CAS(Compare And Swap-------->it works on the CPU)







Executor(I)
--------

single method in parent interface

ExecutorService(I)
---------------

multiple methods in child interface of Excutor(I)


ThreadPoolExcutor(C)
-----------------
this is the concreate class of ExecutorService(I)


public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler
)


1.user defined thread vs predefined thread using executor framework

2.user defined thread------------->not reuseable(more context switching,less processing time)

3.predefined thread using executor framework----------->reuseable(less context switching,more processing time)----------->can we use 2 cpu in single machine?
how intercommunication

4.completeablefuture async vs kafka async communication

imp
---

5.minimum thread number vs maximum thread number

6.minimum thread are busy then place in queue otherwise dont use queue(assume queue size 5 only)

7.if queue size also full then only enable maximum thread number for new task(note:-dont use maximum thread number for old task whatever in the queue)

8.if maximum thread number also full then only rejected the task 

note:- 

1.use maximum thread number after queue full

2.initially minimum thread number and queue size is the matter after that only went to maximum thread number

minimum thread number(avarage time)

queue size(peak time)

maximum thread number(rare cases if minimum thread number and queue size full)

3.keepAliveTime used when the allowCoreThreadTimeOut property set to true


IMP
---

Generally,the ThreadPool min and max size are depend on various factors

-CPU Cores
-JVM Memory
-Task Nature(CPU Intensive or I/O Intensive)
-Concurrency Requirement(Want high or medium or low
-Memory Required to process a request
-Throughput etc.


Max No of thread=No.of CPU Core * (1+Request waiting time/processing time)

Max no of active tasks=Task Arrival rate * Task execution time



Daemon thread vs user thread
----------------------------

1.Daemon thread uses setter method that used to set flag then only act as Daemon thread

2.User thread not uses setter method that is called user thread

RejectedExecutionHandler
------------------------

1.new ThreadPoolExecutor.AbortPolicy(just return error)

2.new ThreadPoolExecutor.CallerRunsPolicy(when calling then rejected------------>but not at called side)

3.new ThreadPoolExecutor.DiscardPolicy(silently rejected without throwing error)

4.new ThreadPoolExecutor.DiscardOldestPolicy


life cycle of thread pool executor
----------------------------------

1.running(accepting new tasks by using submit task while thread pool executor running)
2.shutdown
----------

----->accepting existing pipeline in progress tasks but not new tasks)

----->whatever accepting existing pipeline in progress tasks but not new tasks(shutdown) after that release threads to thread pool

3.stop
------

----->force shutdown(not accepting existing pipeline in progress tasks and also new tasks)

----->whatever not accepting existing pipeline in progress tasks and also new tasks(stop) after that force shutdown and then release threads to thread pool

4.terminated
------------

terminated method used to check shutdown and stop cases threads released to thread pool executor or not
		

Blocking queue
--------------
1.array(static):- bounded queue
2.linkedlist(dynamic):- unbounded queue

ThreadFactory
-------------
1.thread name 
2.thread priority
3.thread daemon flag


Future
------
submit()

CompleteableFuture
------------------

1.supplyAsync()
2.thenApply() and thenApplyAsync()---------->no ordering
3.thenCompose() and thenComposeAsync()---------->ordering
4.thenAccept() and thenAcceptAsync()----------->end part 
5.thenCombine() and thenCombineAsync()--------->combine 2 completeable future






| Feature             | FixedThreadPool        | CachedThreadPool              | ForkJoinPool                       |
| ------------------- | ---------------------- | ----------------------------- | ---------------------------------- |
| **Thread Count**    | Fixed (user-defined)   | Dynamic (grows as needed)     | Default = number of CPU cores      |
| **Task Queue**      | Unbounded queue        | SynchronousQueue (no queue)   | Work-stealing queues (per thread)  |
| **Thread Reuse**    | Yes                    | Yes                           | Yes                                |
| **Idle Timeout**    | No                     | Yes (60 seconds)              | Yes (managed internally)           |
| **Thread Creation** | Reuses fixed threads   | Creates new threads on demand | Uses worker threads per CPU core   |
| **Use Case**        | Steady/controlled load | Many short-lived tasks        | Parallel recursive CPU-bound tasks |
| **Risk**            | Task pile-up (memory)  | Unbounded threads → OOM risk  | Complex to debug & manage threads  |






| Case | Scenario                                                           | Submission Queue  | Work-Stealing Deques         | Thread States                     | Thread-1 Action                                           |
| ---- | ------------------------------------------------------------------ | ----------------- | ---------------------------- | --------------------------------- | --------------------------------------------------------- |
| 1    | 2 threads, 3 tasks in queue; Thread-2 busy, forks subtask-1        | Non-empty         | `subtask-1` in Thread-2      | Thread-1 free, Thread-2 busy      | Picks next task from submission queue                     |
| 2    | 2 threads, 3 tasks; `subtask-1` already in deque; Thread-2 busy    | Non-empty         | `subtask-1` in Thread-2      | Thread-1 free, Thread-2 busy      | Picks next task from submission queue                     |
| 3    | 2 threads, no submission queue; Thread-2 forks `subtask-1`         | Empty             | `subtask-1` in Thread-2      | Thread-1 free, Thread-2 busy      | Steals `subtask-1` from Thread-2 and processes it         |
| 4    | 2 threads, 3 tasks in queue; both threads idle, deques empty       | Non-empty         | Empty                        | Thread-1 and Thread-2 idle        | Thread-1 picks task from submission queue                 |
| 5    | Thread-1 forks multiple subtasks; Thread-2 idle                    | Depends           | `sub1`, `sub2`, `sub3` in T1 | Thread-1 busy, Thread-2 idle      | Thread-2 steals `sub1` (FIFO) from Thread-1               |
| 6    | Thread-1 forks subtasks but **never joins** them; Thread-2 idle    | Depends           | `sub1`, `sub2` in T1         | Thread-1 busy, Thread-2 idle      | Thread-2 steals and processes, but results might be lost  |
| 7    | Deep recursion forks thousands of tasks in Thread-1; Thread-2 busy | Depends           | Large deque in Thread-1      | Thread-1 very busy, Thread-2 busy | Thread-1 may starve own earlier tasks (LIFO), risk of OOM |
| 8    | All threads idle; new task submitted asynchronously                | Becomes non-empty | Empty                        | Thread-1 and Thread-2 idle        | Thread-1 or Thread-2 picks new task from submission queue |



Submit(Runnable task)



shutdown()

awaitTermination()

shutdownNow()



schedule(Runnable command, long delay, TimeUnit unit)	Executes a one-time task after a specified delay.
schedule(Callable<V> callable, long delay, TimeUnit unit)	Schedules a Callable to execute after a delay.
scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)	Repeatedly executes the task at a fixed rate, starting after the initial delay.
scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)	Repeatedly executes the task with a fixed delay between the end of one execution and the start of the next.
shutdown()	Gracefully shuts down the executor after completing current tasks.
shutdownNow()	Attempts to stop all executing tasks immediately.
getQueue()	Returns the queue of tasks waiting to be executed.
getPoolSize()	Returns the current number of threads in the pool.
getActiveCount()	Returns the number of actively executing threads.




Executor

ThreadPoolExecutor ✅
ScheduledThreadPoolExecutor ✅
ForkJoinPool ✅   

vs

Executor executor1 = Executors.newFixedThreadPool(4);         // ThreadPoolExecutor
Executor executor2 = Executors.newCachedThreadPool();         // ThreadPoolExecutor
Executor executor3 = Executors.newSingleThreadExecutor();     // ThreadPoolExecutor
Executor executor4 = Executors.newScheduledThreadPool(2);     // ScheduledThreadPoolExecutor
Executor executor5 = ForkJoinPool.commonPool();               // ForkJoinPool




JVM---------------->platform thread

platform thread around the os thread



Jvm wrapper for platform thread
Each Thread has Thread local class
Thread local class has Thread local variable
Here once set the value to thread local variable
Need to remove is best practice because thread local variable specific to thread but not task
Jvm is mediator between os thread and platform thread
One to mapping between platform thread and os thread
Disadvantages
1.Thread takes time for creation
2.ThreadPoolExecutor also takes time but less compared to thread
3.in thread, internally db calls that time also thread takes time
Virtual thread introduced in java 19
Virtual thread creates and managed by jvm
Whenever thread want to run that time virtual thread attached with os thread
Whenever the thread wants to wait state that time virtual thread detached with os thread
Ex: 2 os thread and many  no of virtual threads
